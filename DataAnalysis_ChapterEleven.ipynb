{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36e54627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 10, 13, 17, 11, 7, 861753)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021 10 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(days=926, seconds=56700)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "926"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "56700"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types in datetime module page 325\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Chapter 11 - Time Series:\n",
    "Anything that is observed, measured at many points in time forms a time series.\n",
    "Many time series are fixed frequency,\n",
    "which is to say that data points coour at regular intervals according to some rule,\n",
    "such as every 15 secs, 5 mins, or per month. Time Series can also be irregular without fixed unit\n",
    "of time or offset between units. How to mark and refer to time series data depends on the application\n",
    "and you may have one of the following:\n",
    "    * Timestamps specific instants in time\n",
    "    * Fixed periods, such as the month January 2007 of the  full year 2010\n",
    "    * Intervals of time, indicated by a start and end timestamp.\n",
    "        Periods can be thought of as special cases of intervals\n",
    "    * Experiment or elapsed time;\n",
    "        each timestamp is a measure of time relative to a particular start time:\n",
    "            (the diameter of a cookie baking each second sicne being placed in the oven)\n",
    "\"\"\"\n",
    "# Date and Time Data Types and Tools \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "display(now)\n",
    "\n",
    "print(now.year, now.month, now.day)\n",
    "\n",
    "# datime stores both the date and time down to the microsecond.\n",
    "# timedelta represents the temporal difference between two datetime objects:\n",
    "\n",
    "delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)\n",
    "\n",
    "display(delta)\n",
    "\n",
    "display(delta.days)\n",
    "\n",
    "display(delta.seconds)\n",
    "\n",
    "# add / subtract a timedelta | multiple thereof to datetime object to yield a new shifed object\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "start + timedelta(12)\n",
    "\n",
    "print('Types in datetime module page 325')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066ca521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2011-01-03 00:00:00'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'2011-01-03'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datetime format specification page 325\n"
     ]
    }
   ],
   "source": [
    "# Converting Between String and Datetime \n",
    "# format datetime object & pd Timestamp object,using srt|strftime method, pass f specification\n",
    "\n",
    "stamp = datetime(2011, 1, 3)\n",
    "\n",
    "display(str(stamp))\n",
    "\n",
    "display(stamp.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print('Datetime format specification page 325')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc19bebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 3, 0, 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 3, 0, 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['7/6/2011', '8/6/2011']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2011, 7, 6, 0, 0), datetime.datetime(2011, 8, 6, 0, 0)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 3, 0, 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(1997, 1, 31, 22, 45)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 12, 6, 0, 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-07-06 12:00:00', '2011-08-06 00:00:00'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locale-specific date formatting\n"
     ]
    }
   ],
   "source": [
    "# Use many of the same format codes to conver strings to dates using datetime.strptime\n",
    "    # some codes like %F cannot be used\n",
    "    \n",
    "value = '2011-01-03'\n",
    "display(datetime.strptime(value, '%Y-%m-%d'))\n",
    "\n",
    "display(datetime(2011, 1, 3, 0, 0))\n",
    "\n",
    "daatestrs = ['7/6/2011', '8/6/2011']\n",
    "\n",
    "display(daatestrs)\n",
    "\n",
    "display([datetime.strptime(x, '%m/%d/%Y') for x in daatestrs])\n",
    "\n",
    "# datetime.strptime is a good way to parse a date with a known format.\n",
    "# avaoid writing format sects eachtime use the parser.parse method in 3rd-party dateutil package\n",
    "\n",
    "from dateutil.parser import parse\n",
    "\n",
    "display(parse('2011-01-03'))\n",
    "\n",
    "# dateutil is capable of parsing most human -intelligible date representaions\n",
    "\n",
    "display(parse('Jan 31, 1997 10:45 PM'))\n",
    "\n",
    "# for day appearing before month pass dayfirst=True to indicate this\n",
    "\n",
    "display(parse('6/12/2021', dayfirst=True))\n",
    "\n",
    "# pd uses arr as axis idx|col in df.to_datetime parses different kinds of date representations.\n",
    "\n",
    "datesrts = ['2011-07-06 12:00:00', '2011-08-06 00:00:00']\n",
    "\n",
    "display(pd.to_datetime(datesrts))\n",
    "\n",
    "print('Locale-specific date formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c31fe4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02   -1.671792\n",
       "2011-01-05   -1.986466\n",
       "2011-01-07    0.147014\n",
       "2011-01-08    0.925276\n",
       "2011-01-10   -0.795081\n",
       "2011-01-12   -1.328955\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-01-02', '2011-01-05', '2011-01-07', '2011-01-08',\n",
       "               '2011-01-10', '2011-01-12'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-01-02 00:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Time Series Basics:\n",
    "    A basic kind of time series object in pd is a series indexed by timestamps,\n",
    "    which is often represented external to pd as py strings or datetime objects:\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "dates = [datetime(2011, 1, 2), datetime(2011, 1, 5),\n",
    "         datetime(2011, 1, 7), datetime(2011, 1, 8),\n",
    "         datetime(2011, 1, 10), datetime(2011, 1, 12)]\n",
    "\n",
    "ts = pd.Series(np.random.randn(6), index=dates)\n",
    "\n",
    "display(ts)\n",
    "\n",
    "# Under the hood, these satetime objects have been put in a datetimeIndex:\n",
    "\n",
    "display(ts.index)\n",
    "\n",
    "# Like other Series, arithmetic operations between differently indexed time series automatically \n",
    "# aling on the dates:\n",
    "ts + ts[::2]\n",
    "\n",
    "# Scalar values from a DatietimeIndex are pd timsestamp objects:\n",
    "\n",
    "stamp = ts.index[0]\n",
    "\n",
    "display(stamp)\n",
    "\n",
    "# A timestamp can be substitues anuwhere you would use a datetime object. Also it can store \n",
    "# frequency information and usntands how to do time zone conversions and other manipulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01d365d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14701397338144617"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.7950808562427746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.7950808562427746"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-01    1.262395\n",
       "2000-01-02   -1.940803\n",
       "2000-01-03   -1.502487\n",
       "2000-01-04   -0.161514\n",
       "2000-01-05   -1.768813\n",
       "                ...   \n",
       "2002-09-22   -0.427228\n",
       "2002-09-23   -0.274869\n",
       "2002-09-24    0.043071\n",
       "2002-09-25    0.649159\n",
       "2002-09-26   -0.390599\n",
       "Freq: D, Length: 1000, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2001-01-01   -2.044789\n",
       "2001-01-02    0.555724\n",
       "2001-01-03   -0.301791\n",
       "2001-01-04   -0.439534\n",
       "2001-01-05   -1.036867\n",
       "Freq: D, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2001-05-01   -2.515559\n",
       "2001-05-02    0.486204\n",
       "2001-05-03   -1.380313\n",
       "2001-05-04    1.687745\n",
       "2001-05-05   -0.360070\n",
       "Freq: D, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2011-01-07    0.147014\n",
       "2011-01-08    0.925276\n",
       "2011-01-10   -0.795081\n",
       "2011-01-12   -1.328955\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2011-01-07    0.147014\n",
       "2011-01-08    0.925276\n",
       "2011-01-10   -0.795081\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2011-01-02   -1.671792\n",
       "2011-01-05   -1.986466\n",
       "2011-01-07    0.147014\n",
       "2011-01-08    0.925276\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Indexing, Selection, Subsetting\n",
    "# Time series behaves like any other pd.Series when you are indexing and selecting data based on label:\n",
    "\n",
    "stamp = ts.index[2]\n",
    "\n",
    "display(ts[stamp])\n",
    "\n",
    "# As a convenience, you can also pass s string that is interpretable as a date:\n",
    "\n",
    "display(ts['1/10/2011'])\n",
    "\n",
    "display(ts['20110110'])\n",
    "\n",
    "# For longer time series, a year or only a year and month can be passed to easily selct slices of data:\n",
    "\n",
    "longer_ts = pd.Series(np.random.randn(1000),\n",
    "                      index=pd.date_range('1/1/2000', periods=1000))\n",
    "\n",
    "display(longer_ts)\n",
    "\n",
    "display(longer_ts['2001'][:5])\n",
    "\n",
    "# Here the string \"2001\" is interpreted as a year and selects that time period. \n",
    "# This works if you specify the month:\n",
    "\n",
    "display(longer_ts['2001-05'][:5])\n",
    "\n",
    "# Slicing with datime onjects works as well:\n",
    "\n",
    "display(ts[datetime(2011, 1, 7):])\n",
    "\n",
    "# You can slice with timestamps not contained in a time series to perform a range query:\n",
    "\n",
    "display(ts['1/6/2011':'1/11/2011'])\n",
    "\n",
    "# Modifications on the slice will be reflactied in ther original data\n",
    "\n",
    "# These is an equivalent instance methos , trucate, that slices a Series betweeen two dates:\n",
    "\n",
    "display(ts.truncate(after='1/9/2011'))\n",
    "\n",
    "# All this holds for the df as well, indexing on its rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1548cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Series with Duplucate Indices \n",
    "# In some apllications, there may be multiple data obsevations falling on a particualr timmestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d51dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',\n",
       "               '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',\n",
       "               '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',\n",
       "               '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',\n",
       "               '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20',\n",
       "               '2012-04-21', '2012-04-22', '2012-04-23', '2012-04-24',\n",
       "               '2012-04-25', '2012-04-26', '2012-04-27', '2012-04-28',\n",
       "               '2012-04-29', '2012-04-30', '2012-05-01', '2012-05-02',\n",
       "               '2012-05-03', '2012-05-04', '2012-05-05', '2012-05-06',\n",
       "               '2012-05-07', '2012-05-08', '2012-05-09', '2012-05-10',\n",
       "               '2012-05-11', '2012-05-12', '2012-05-13', '2012-05-14',\n",
       "               '2012-05-15', '2012-05-16', '2012-05-17', '2012-05-18',\n",
       "               '2012-05-19', '2012-05-20', '2012-05-21', '2012-05-22',\n",
       "               '2012-05-23', '2012-05-24', '2012-05-25', '2012-05-26',\n",
       "               '2012-05-27', '2012-05-28', '2012-05-29', '2012-05-30',\n",
       "               '2012-05-31', '2012-06-01'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-04-01', '2012-04-02', '2012-04-03', '2012-04-04',\n",
       "               '2012-04-05', '2012-04-06', '2012-04-07', '2012-04-08',\n",
       "               '2012-04-09', '2012-04-10', '2012-04-11', '2012-04-12',\n",
       "               '2012-04-13', '2012-04-14', '2012-04-15', '2012-04-16',\n",
       "               '2012-04-17', '2012-04-18', '2012-04-19', '2012-04-20'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-05-13', '2012-05-14', '2012-05-15', '2012-05-16',\n",
       "               '2012-05-17', '2012-05-18', '2012-05-19', '2012-05-20',\n",
       "               '2012-05-21', '2012-05-22', '2012-05-23', '2012-05-24',\n",
       "               '2012-05-25', '2012-05-26', '2012-05-27', '2012-05-28',\n",
       "               '2012-05-29', '2012-05-30', '2012-05-31', '2012-06-01'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 11.3: Date Ranges, Frequencies, and Shifting\n",
    "\n",
    "You can convert the sample time series to be fixed daily frequency by calling resample:\n",
    "\"\"\"\n",
    "\n",
    "ts\n",
    "\n",
    "resampler = ts.resample(\"D\") # D daily frequency; Here we use base frequencies and multiples thereof\n",
    "\n",
    "# Generating Date Ranges: pd.date_range is responsible for generating a DatatimeIndex \n",
    "\n",
    "index = pd.date_range('2012-04-01', '2012-06-01')\n",
    "\n",
    "display(index)\n",
    "\n",
    "# By default, date_range genarates daily timestamps. If you pass only a strat or end date\n",
    "# You must pass a number of periods to generate:\n",
    "\n",
    "may = pd.date_range(start='2012-04-01', periods=20)\n",
    "        \n",
    "june = pd.date_range(end='2012-06-01', periods=20)\n",
    "\n",
    "display(may)\n",
    "                     \n",
    "display(june)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51021f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-05-02 12:56:31', '2012-05-03 12:56:31',\n",
       "               '2012-05-04 12:56:31', '2012-05-05 12:56:31',\n",
       "               '2012-05-06 12:56:31'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-05-02', '2012-05-03', '2012-05-04', '2012-05-05',\n",
       "               '2012-05-06'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The start and end dates define strict boundaries for the generated date index.\n",
    "\n",
    "Base time series frequencies (not comphensive page 355)\n",
    "\n",
    "date_range by default preserves the time (in any) of the start or end stomestamp:\n",
    "\"\"\"                     \n",
    "non_mod = pd.date_range('2012-05-02 12:56:31',\n",
    "              periods=5)\n",
    "\n",
    "# To mormalized to mifnight as a convention. Use the normalize option:\n",
    "\n",
    "norm = pd.date_range('2012-05-02 12:56:31',\n",
    "              periods=5,\n",
    "              normalize=True)\n",
    "\n",
    "display(non_mod)\n",
    "\n",
    "display(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3d39b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Hour>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<4 * Hours>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 04:00:00',\n",
       "               '2000-01-01 08:00:00', '2000-01-01 12:00:00',\n",
       "               '2000-01-01 16:00:00', '2000-01-01 20:00:00',\n",
       "               '2000-01-02 00:00:00', '2000-01-02 04:00:00',\n",
       "               '2000-01-02 08:00:00', '2000-01-02 12:00:00',\n",
       "               '2000-01-02 16:00:00', '2000-01-02 20:00:00',\n",
       "               '2000-01-03 00:00:00'],\n",
       "              dtype='datetime64[ns]', freq='4H')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2021-01-01 00:00:00', '2021-01-01 01:30:00',\n",
       "               '2021-01-01 03:00:00', '2021-01-01 04:30:00',\n",
       "               '2021-01-01 06:00:00', '2021-01-01 07:30:00',\n",
       "               '2021-01-01 09:00:00', '2021-01-01 10:30:00',\n",
       "               '2021-01-01 12:00:00', '2021-01-01 13:30:00'],\n",
       "              dtype='datetime64[ns]', freq='90T')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Frequencies and Date Offsets \n",
    "\n",
    "from pandas.tseries.offsets import Hour, Minute\n",
    "\n",
    "hour = Hour()\n",
    "\n",
    "display(hour)\n",
    "\n",
    "# You can define a multipkle of an offset by passing an integer:\n",
    "\n",
    "four_hours = Hour(4)\n",
    "\n",
    "display(four_hours)\n",
    "\n",
    "# Putting an interger before the base frequency creates a mulitple\n",
    "\n",
    "multiple = pd.date_range(\"2000-01-01\", '2000-01-03', freq='4h')\n",
    "\n",
    "display(multiple)\n",
    "\n",
    "# Many offsets can be combined together by addition:\n",
    "\n",
    "Hour(2) + Minute(30)\n",
    "\n",
    "# Pass a frequency strings, like '1h30min', that will effectively be parsed to the expressing:\n",
    "\n",
    "custom_mod = pd.date_range('2021-01-01', periods=10, freq='1h30min')\n",
    "\n",
    "display(custom_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8e83e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-17', '2020-02-21', '2020-03-20', '2020-04-17',\n",
       "               '2020-05-15', '2020-06-19', '2020-07-17', '2020-08-21'],\n",
       "              dtype='datetime64[ns]', freq='WOM-3FRI')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-31    0.323411\n",
       "2000-02-29    0.314570\n",
       "2000-03-31   -0.675444\n",
       "2000-04-30    1.229575\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-31         NaN\n",
       "2000-02-29         NaN\n",
       "2000-03-31    0.323411\n",
       "2000-04-30    0.314570\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-31   -0.675444\n",
       "2000-02-29    1.229575\n",
       "2000-03-31         NaN\n",
       "2000-04-30         NaN\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-31         NaN\n",
       "2000-02-29   -0.027337\n",
       "2000-03-31   -3.147198\n",
       "2000-04-30   -2.820394\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-03-31    0.323411\n",
       "2000-04-30    0.314570\n",
       "2000-05-31   -0.675444\n",
       "2000-06-30    1.229575\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-02-03    0.323411\n",
       "2000-03-03    0.314570\n",
       "2000-04-03   -0.675444\n",
       "2000-05-03    1.229575\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-31 01:30:00    0.323411\n",
       "2000-02-29 01:30:00    0.314570\n",
       "2000-03-31 01:30:00   -0.675444\n",
       "2000-04-30 01:30:00    1.229575\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-11-20 00:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-11-30 00:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-12-31 00:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-11-30 00:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-10-31 00:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-15   -0.348630\n",
       "2000-01-19   -0.242899\n",
       "2000-01-23    1.531511\n",
       "2000-01-27    0.800669\n",
       "2000-01-31   -1.490771\n",
       "2000-02-04   -1.215172\n",
       "2000-02-08    0.344875\n",
       "2000-02-12   -0.831604\n",
       "2000-02-16   -0.067861\n",
       "2000-02-20    0.889792\n",
       "2000-02-24    1.703046\n",
       "2000-02-28   -0.802500\n",
       "2000-03-03   -0.152938\n",
       "2000-03-07    0.916087\n",
       "2000-03-11   -0.515430\n",
       "2000-03-15    0.025064\n",
       "2000-03-19    3.203713\n",
       "2000-03-23    0.092109\n",
       "2000-03-27    0.141511\n",
       "2000-03-31    0.733799\n",
       "Freq: 4D, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1999-12-31    0.435163\n",
       "2000-01-31   -0.183774\n",
       "2000-02-29    0.530017\n",
       "2000-03-31    0.733799\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-31    0.049976\n",
       "2000-02-29    0.002939\n",
       "2000-03-31    0.555489\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Week of month dates: WOM enables you to get dates like the third Friday of each month:\n",
    "\n",
    "rng = pd.date_range('2020-01-01', '2020-09-01', freq='WOM-3FRI')\n",
    "\n",
    "display(rng)\n",
    "\n",
    "# Shifting (Leading and Lagging) Data\n",
    "# \"shifting\" refers to moving data backward and foward through time.\n",
    "# Both Series and df have shift method for doing naive shifts forward or abckeard\n",
    "# Leaving index unmodified:\n",
    "\n",
    "ts = pd.Series(np.random.randn(4),\n",
    "              index=pd.date_range('1/1/2000', periods=4, freq='M'))\n",
    "\n",
    "display(ts)\n",
    "\n",
    "display(ts.shift(2))\n",
    "\n",
    "display(ts.shift(-2))\n",
    "\n",
    "# A common use of shift is computing % change in a time series or multiple series as df columns.\n",
    "\n",
    "display(ts / ts.shift(1) -1)\n",
    "\n",
    "# Frequency is known, it can passed to shitf to advance the timestamps instead of simple the data\n",
    "\n",
    "display(ts.shift(2, freq='M'))\n",
    "\n",
    "# Other frequencies can be apssed, too, giving you some flaexibility in how to lead and lag data\n",
    "\n",
    "display(ts.shift(3, freq='D'))\n",
    "\n",
    "display(ts.shift(1, freq='90T'))\n",
    "\n",
    "# The T stands for minutes. Note that the freq parameter here indicates the offset to apply to the\n",
    "# timestamps, but it does not change the underlying frequncy of the data, if any\n",
    "\n",
    "# Shifting, dates wiiht offsets; The pandas date ofsets can also be used with datetime|Timestamp\n",
    "\n",
    "from pandas.tseries.offsets import Day, MonthEnd\n",
    "\n",
    "now = datetime(2011, 11, 17)\n",
    "\n",
    "display(now + 3 * Day())\n",
    "\n",
    "# If you add an anchored offset like MonthEnd, the first increment will 'roll forward' \n",
    "# a date to the next date according to the frequency rule:\n",
    "\n",
    "display(now + MonthEnd())\n",
    "\n",
    "display(now + MonthEnd(2))\n",
    "\n",
    "# Anchored offets can explicitly 'roll' dates forward or backward by simply suning there \n",
    "# rollfowaed and rollback methods,respectively:\n",
    "\n",
    "offset = MonthEnd()\n",
    "\n",
    "display(offset.rollforward(now))\n",
    "\n",
    "display(offset.rollback(now))\n",
    "\n",
    "# A creative use of date offsets in to use these methods with groupby:\n",
    "\n",
    "ts = pd.Series(np.random.randn(20),\n",
    "              index=pd.date_range('1/15/2000', periods=20, freq='4d'))\n",
    "\n",
    "display(ts)\n",
    "\n",
    "display(ts.groupby(offset.rollback).mean())\n",
    "\n",
    "display(ts.resample('M').mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e23a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-09 09:30:00', '2012-03-10 09:30:00',\n",
       "               '2012-03-11 09:30:00', '2012-03-12 09:30:00',\n",
       "               '2012-03-13 09:30:00', '2012-03-14 09:30:00'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2020-01-17    0.512878\n",
       "2020-02-21    0.206506\n",
       "2020-03-20    0.691789\n",
       "2020-04-17    0.800493\n",
       "2020-05-15    0.785732\n",
       "2020-06-19    0.388258\n",
       "2020-07-17    0.290691\n",
       "2020-08-21    0.569047\n",
       "Freq: WOM-3FRI, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-09 09:30:00+00:00', '2012-03-10 09:30:00+00:00',\n",
       "               '2012-03-11 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n",
       "               '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',\n",
       "               '2012-03-15 09:30:00+00:00', '2012-03-16 09:30:00+00:00',\n",
       "               '2012-03-17 09:30:00+00:00', '2012-03-18 09:30:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq='D')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2020-01-17 00:00:00+00:00    0.512878\n",
       "2020-02-21 00:00:00+00:00    0.206506\n",
       "2020-03-20 00:00:00+00:00    0.691789\n",
       "2020-04-17 00:00:00+00:00    0.800493\n",
       "2020-05-15 00:00:00+00:00    0.785732\n",
       "2020-06-19 00:00:00+00:00    0.388258\n",
       "2020-07-17 00:00:00+00:00    0.290691\n",
       "2020-08-21 00:00:00+00:00    0.569047\n",
       "Freq: WOM-3FRI, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-17 00:00:00+00:00', '2020-02-21 00:00:00+00:00',\n",
       "               '2020-03-20 00:00:00+00:00', '2020-04-17 00:00:00+00:00',\n",
       "               '2020-05-15 00:00:00+00:00', '2020-06-19 00:00:00+00:00',\n",
       "               '2020-07-17 00:00:00+00:00', '2020-08-21 00:00:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq='WOM-3FRI')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2020-01-16 19:00:00-05:00    0.512878\n",
       "2020-02-20 19:00:00-05:00    0.206506\n",
       "2020-03-19 20:00:00-04:00    0.691789\n",
       "2020-04-16 20:00:00-04:00    0.800493\n",
       "2020-05-14 20:00:00-04:00    0.785732\n",
       "2020-06-18 20:00:00-04:00    0.388258\n",
       "2020-07-16 20:00:00-04:00    0.290691\n",
       "2020-08-20 20:00:00-04:00    0.569047\n",
       "Freq: WOM-3FRI, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2020-01-17 05:00:00+00:00    0.512878\n",
       "2020-02-21 05:00:00+00:00    0.206506\n",
       "2020-03-20 04:00:00+00:00    0.691789\n",
       "2020-04-17 04:00:00+00:00    0.800493\n",
       "2020-05-15 04:00:00+00:00    0.785732\n",
       "2020-06-19 04:00:00+00:00    0.388258\n",
       "2020-07-17 04:00:00+00:00    0.290691\n",
       "2020-08-21 04:00:00+00:00    0.569047\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2020-01-17 06:00:00+01:00    0.512878\n",
       "2020-02-21 06:00:00+01:00    0.206506\n",
       "2020-03-20 05:00:00+01:00    0.691789\n",
       "2020-04-17 06:00:00+02:00    0.800493\n",
       "2020-05-15 06:00:00+02:00    0.785732\n",
       "2020-06-19 06:00:00+02:00    0.388258\n",
       "2020-07-17 06:00:00+02:00    0.290691\n",
       "2020-08-21 06:00:00+02:00    0.569047\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2020-01-17 00:00:00+08:00', '2020-02-21 00:00:00+08:00',\n",
       "               '2020-03-20 00:00:00+08:00', '2020-04-17 00:00:00+08:00',\n",
       "               '2020-05-15 00:00:00+08:00', '2020-06-19 00:00:00+08:00',\n",
       "               '2020-07-17 00:00:00+08:00', '2020-08-21 00:00:00+08:00'],\n",
       "              dtype='datetime64[ns, Asia/Shanghai]', freq=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# TIme Zone Handling\n",
    "\n",
    "Working with time zones generally considered one of most unpleasnt part of timeseries manipulation\n",
    "Coordinated Universal Time or UTC, which is the international standard. \n",
    "Timezones are expressed as offsets from UTC.\n",
    "\"\"\"\n",
    "\n",
    "import pytz\n",
    "\n",
    "display(pytz.common_timezones[-5:])\n",
    "\n",
    "# To get a time zone object form pytz, use pytz.timezone:\n",
    "\n",
    "tz = pytz.timezone('America/New_York')\n",
    "\n",
    "display(tz)\n",
    "\n",
    "# Time Zone Localization and Conversion: times series in pd are time zine naive.\n",
    "\n",
    "png = pd.date_range('3/9/2012 9:30', periods=6, freq='D')\n",
    "\n",
    "display(png)\n",
    "\n",
    "ts = pd.Series(np.random.rand(len(rng)), index=rng)\n",
    "\n",
    "display(ts)\n",
    "\n",
    "# Time index's tz fiels is None:\n",
    "\n",
    "print(ts.index.tz)\n",
    "\n",
    "# Date ranges can be generatged with a time zone set:\n",
    "\n",
    "geneatedZone = pd.date_range('3/9/2012 9:30', periods=10, freq='D', tz='UTC')\n",
    "display(geneatedZone)\n",
    "\n",
    "# Conversion from naice to localized is handled by the tz_localize method:\n",
    "ts_utc = ts.tz_localize('UTC')\n",
    "\n",
    "display(ts_utc)\n",
    "\n",
    "display(ts_utc.index)\n",
    "\n",
    "# Once a timezone had been localized to a particular timezone,\n",
    "# conver it to another with tz_convert:\n",
    "display(ts_utc.tz_convert('America/New_York'))\n",
    "\n",
    "# localize to EST and convert to, say, UTC or Berlin time:\n",
    "\n",
    "ts_eastern = ts.tz_localize('America/New_York')\n",
    "\n",
    "display(ts_eastern.tz_convert('UTC'))\n",
    "\n",
    "display(ts_eastern.tz_convert(\"Europe/Berlin\"))\n",
    "\n",
    "# tz_localize and tz_convert are also methods on datatimeindex:\n",
    "\n",
    "display(ts.index.tz_localize('Asia/Shanghai'))\n",
    "\n",
    "# Localizing naive timestmaps also checks for ambiguous or non-exixtent times around daylight time trnascaations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d41c715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-03-11 23:00:00-0500', tz='America/New_York')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-03-12 04:00:00+0300', tz='Europe/Moscow')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1299902400000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1299902400000000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-03-11 01:30:00-0500', tz='US/Eastern')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-03-11 03:30:00-0400', tz='US/Eastern')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-11-04 00:30:00-0400', tz='US/Eastern')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-03-11 04:30:00-0400', tz='US/Eastern')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2012-03-07 09:30:00    0.351314\n",
       "2012-03-08 09:30:00    0.190671\n",
       "2012-03-09 09:30:00   -0.212917\n",
       "2012-03-12 09:30:00    1.356670\n",
       "2012-03-13 09:30:00   -1.894094\n",
       "2012-03-14 09:30:00   -0.599570\n",
       "2012-03-15 09:30:00    0.765905\n",
       "2012-03-16 09:30:00   -0.293791\n",
       "2012-03-19 09:30:00    0.855750\n",
       "2012-03-20 09:30:00    0.648576\n",
       "Freq: B, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-07 09:30:00+00:00', '2012-03-08 09:30:00+00:00',\n",
       "               '2012-03-09 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n",
       "               '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',\n",
       "               '2012-03-15 09:30:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq=None)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Operations with Time Zone - Aware Timestamp Objects:\n",
    "# Timestamp obj can be localized from naive to timezone-aware and converter one time zone to another\n",
    "stamp = pd.Timestamp('2011-03-12 04:00')\n",
    "\n",
    "stamp_utc = stamp.tz_localize('utc')\n",
    "\n",
    "display(stamp_utc.tz_convert('America/New_York'))\n",
    "\n",
    "# One can also pass the timezone while creating the timestamp\n",
    "\n",
    "stam_moscow = pd.Timestamp('2011-03-12 4:00', tz='Europe/Moscow')\n",
    "\n",
    "display(stam_moscow)\n",
    "\n",
    "# Timezone-aware Timestamp objects internally store a UTC timestamp value as nanoseconds\n",
    "# This UTC value is invariant between time zone conversions:\n",
    "\n",
    "display(stamp_utc.value)\n",
    "\n",
    "display(stamp_utc.tz_convert('America/New_York').value)\n",
    "\n",
    "# when performing time arithmetic using pandas DateOffset objects,\n",
    "# pd prespects daylight saving tome transactions where possible.\n",
    "# Here we construct tomestamps that occur right before DTF transitions (Forward and Backward)\n",
    "# First, 30 minutes before transitioning to DST:\n",
    "\n",
    "from pandas.tseries.offsets import Hour\n",
    "\n",
    "stamp = pd.Timestamp('2012-03-11 01:30', tz='US/Eastern')\n",
    "display(stamp)\n",
    "\n",
    "display(stamp + Hour())\n",
    "\n",
    "# Then, 90 minutes before transitiong out of DST\n",
    "\n",
    "stamp1 = pd.Timestamp('2012-11-04 00:30:00-0400', tz='US/Eastern')\n",
    "display(stamp1)\n",
    "\n",
    "display(stamp + 2 * Hour())\n",
    "\n",
    "# Operations Between Different Time Zones \n",
    "# IF two time series with different timezones are combined, the result will be UTC.\n",
    "# Since the timestamps are stored under the hood in utc,\n",
    "# this is a strightforward operation and requies no conversion\n",
    "\n",
    "rng1 = pd.date_range('3/7/2012 9:30', periods=10, freq='B')\n",
    "\n",
    "ts1 = pd.Series(np.random.randn(len(rng1)), index=rng1)\n",
    "\n",
    "display(ts1)\n",
    "\n",
    "ts11 = ts1[:7].tz_localize('Europe/London')\n",
    "\n",
    "ts2 = ts11[2:].tz_convert('Europe/Moscow')\n",
    "\n",
    "result = ts11 + ts2\n",
    "\n",
    "display(result.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e0394ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2007', 'A-DEC')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2012', 'A-DEC')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2005', 'A-DEC')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<7 * YearEnds: month=12>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '2000-06'], dtype='period[M]', freq='M')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01   -0.364017\n",
       "2000-02    0.438591\n",
       "2000-03   -1.718622\n",
       "2000-04    1.091022\n",
       "2000-05   -0.185022\n",
       "2000-06   -2.012804\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2001Q3', '2002Q2', '2003Q1'], dtype='period[Q-DEC]', freq='Q-DEC')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Periods and Period Arithmetic \n",
    "\n",
    "Periods represent timespands, like days, months, quarters, or years.\n",
    "The period class represents this data type, requiring a string or integer and a frquency\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "p = pd.Period(2007, freq='A-DEC')\n",
    "\n",
    "# Here the period object represnts the full timespan from Jan 1 - Dec 31 inclusive.\n",
    "\n",
    "display(p)\n",
    "\n",
    "# COnveniently, adding and subtracting ints from periods shifts by their frequency:\n",
    "\n",
    "display(p + 5)\n",
    "\n",
    "display(p - 2)\n",
    "\n",
    "# if tww periods the dame frequency, their diffrence is the number of units between them\n",
    "\n",
    "display(pd.Period('2014', freq='A-DEC') - p)\n",
    "\n",
    "# regular ranges of periods cna be constructed with the period_range function\n",
    "\n",
    "per_rng = pd.period_range('2000-01-01', '2000-06-30', freq='M')\n",
    "display(per_rng)\n",
    "\n",
    "# The PeriodIndex class stores a sequence of periods and can serve as\n",
    "# an axis index in any pands data strcuture.\n",
    "\n",
    "display(pd.Series(np.random.randn(6), index=per_rng))\n",
    "\n",
    "# If you have an array of strings, you can also use the PeriodIndex class:\n",
    "\n",
    "values = ['2001Q3', '2002Q2', \"2003Q1\"]\n",
    "\n",
    "indexS = pd.PeriodIndex(values, freq='Q-DEC')\n",
    "\n",
    "display(indexS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "101f2888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2007', 'A-DEC')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2007-01', 'M')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2007-12', 'M')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2007', 'A-JUN')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2006-07', 'M')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2007-06', 'M')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2008', 'A-JUN')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2006    0.838088\n",
       "2007   -1.491177\n",
       "2008    1.219357\n",
       "2009   -0.470802\n",
       "Freq: A-DEC, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2006-12-29    0.838088\n",
       "2007-12-31   -1.491177\n",
       "2008-12-31    1.219357\n",
       "2009-12-31   -0.470802\n",
       "Freq: B, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Period Frequency Conversion\n",
    "Periods and PeriodIndex objects can be converted to another frequency with their asfreq method.\n",
    "\"\"\"\n",
    "\n",
    "p = pd.Period('2007', freq='A-DEC')\n",
    "\n",
    "display(p)\n",
    "\n",
    "display(p.asfreq('M', how='start'))\n",
    "\n",
    "display(p.asfreq('M', how='end'))\n",
    "\n",
    "# One can think of Period('2007', 'A-DEC') as being a sort of cursor pointing to a span of time\n",
    "# subdivided by monthly periods. For a fiscal year ending on a month other than December,\n",
    "# the corresponding monthly subperiods are different:\n",
    "\n",
    "p = pd.Period('2007', 'A-JUN')\n",
    "\n",
    "display(p)\n",
    "\n",
    "display(p.asfreq('M', 'start'))\n",
    "\n",
    "display(p.asfreq('M', 'end'))\n",
    "\n",
    "# When you are converting from high to low frequency, pandas determines the super-period \n",
    "# depending on where the subperiod 'belongs.' For example, in A-JUN frequency,\n",
    "# the month aug-2007 is actually part of the 2008 period:\n",
    "\n",
    "p = pd.Period('Aug-2007', 'M')\n",
    "\n",
    "display(p.asfreq('A-JUN'))\n",
    "\n",
    "# Whole PeriodINdex objects or time series can be similarly converted with the same semantics:\n",
    "\n",
    "rng = pd.period_range('2006', '2009', freq='A-DEC')\n",
    "\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "\n",
    "display(ts)\n",
    "\n",
    "# If we instead wanted the last business day of each year,\n",
    "# we can use the 'B' frequency and indicate that we want the end of the period:\n",
    "\n",
    "display(ts.asfreq('B', how='end'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3081f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2012Q4', 'Q-JAN')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Period('2012-01-30 16:00', 'T')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2012-01-30 16:00:00')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2011Q3    0\n",
       "2011Q4    1\n",
       "2012Q1    2\n",
       "2012Q2    3\n",
       "2012Q3    4\n",
       "2012Q4    5\n",
       "Freq: Q-JAN, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2010-10-28 16:00:00    0\n",
       "2011-01-28 16:00:00    1\n",
       "2011-04-28 16:00:00    2\n",
       "2011-07-28 16:00:00    3\n",
       "2011-10-28 16:00:00    4\n",
       "2012-01-30 16:00:00    5\n",
       "dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Quarterly Period Frequencies \n",
    "\n",
    "\"\"\"\n",
    "Q data is standard in accounting, finance, and other fields.\n",
    "quarterly data is reported realtive to fiscal year end, typically the last calendar or bussiness\n",
    "day of one the 12 months of the year. Thus, the period 2012Q4 has a different meaning depending\n",
    "on fiscal year end. pandas supports all 12 possible quarterly frequencies as Q-JAN through Q-DEC:\n",
    "\n",
    "DIfferent quarterly frequency converntions page 349\n",
    "\"\"\"\n",
    "\n",
    "p = pd.Period('2012Q4', freq='Q-JAN')\n",
    "\n",
    "display(p)\n",
    "\n",
    "# Thus, itls possible to do easy period arithmetic; for example,\n",
    "# to get the timestamp at 4 PM on the second-to-last businees day of the quarter, you could do:\n",
    "\n",
    "p4pm = (p.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60 \n",
    "\n",
    "display(p4pm)\n",
    "\n",
    "display(p4pm.to_timestamp())\n",
    "\n",
    "# You can genarate quarterly ranges using period_range. Arithmetic is indentical, too:\n",
    "\n",
    "rng = pd.period_range('2011Q3', '2012Q4', freq='Q-JAN')\n",
    "\n",
    "ts = pd.Series(np.arange(len(rng)), index=rng)\n",
    "\n",
    "display(ts)\n",
    "\n",
    "new_rng = (rng.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60\n",
    "\n",
    "ts.index = new_rng.to_timestamp()\n",
    "\n",
    "display(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "088282dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-01-31    1.551288\n",
       "2001-02-28    0.197186\n",
       "2001-03-31   -1.141906\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2001-01    1.551288\n",
       "2001-02    0.197186\n",
       "2001-03   -1.141906\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2001-01-31 23:59:59.999999999    1.551288\n",
       "2001-02-28 23:59:59.999999999    0.197186\n",
       "2001-03-31 23:59:59.999999999   -1.141906\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['1959Q1', '1959Q2', '1959Q3', '1959Q4', '1960Q1', '1960Q2',\n",
       "             '1960Q3', '1960Q4', '1961Q1', '1961Q2',\n",
       "             ...\n",
       "             '2007Q2', '2007Q3', '2007Q4', '2008Q1', '2008Q2', '2008Q3',\n",
       "             '2008Q4', '2009Q1', '2009Q2', '2009Q3'],\n",
       "            dtype='period[Q-DEC]', length=203, freq='Q-DEC')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1959Q1    0.00\n",
       "1959Q2    2.34\n",
       "1959Q3    2.74\n",
       "1959Q4    0.27\n",
       "1960Q1    2.31\n",
       "          ... \n",
       "2008Q3   -3.16\n",
       "2008Q4   -8.79\n",
       "2009Q1    0.94\n",
       "2009Q2    3.37\n",
       "2009Q3    3.56\n",
       "Freq: Q-DEC, Name: infl, Length: 203, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# COnverting Timestamps to Periods (and Back)\n",
    "Series and DataFrame objects indexed by timestamps can be converted\n",
    "to periods with the to_period method:\n",
    "\"\"\"\n",
    "\n",
    "rng = pd.date_range('2001-01-01', periods=3, freq='M')\n",
    "\n",
    "ts = pd.Series(np.random.randn(3), index=rng)\n",
    "\n",
    "display(ts)\n",
    "\n",
    "pts = ts.to_period()\n",
    "\n",
    "display(pts)\n",
    "\n",
    "display(pts.to_timestamp(how='end'))\n",
    "\n",
    "# Creating a PeriodIndex from Arrays \n",
    "# Fixed frequency datasests are sometimes stored with timespan information spraed accros multiple cols\n",
    "\n",
    "mac_data = pd.read_csv('macrodata.csv')\n",
    "\n",
    "mac_data[:5]\n",
    "\n",
    "# By passing these arrays to PeriosIndex with a\n",
    "# frequencym you can combine tham to form an index for the DataFrame\n",
    "\n",
    "index = pd.PeriodIndex(year=mac_data.year, quarter = mac_data.quarter,\n",
    "                      freq='Q-DEC')\n",
    "\n",
    "display(index)\n",
    "\n",
    "mac_data.index = index\n",
    "\n",
    "display(mac_data.infl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b2c3abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    0.060191\n",
       "2000-01-02    0.370572\n",
       "2000-01-03   -1.784461\n",
       "2000-01-04    1.605658\n",
       "2000-01-05   -0.585746\n",
       "                ...   \n",
       "2000-04-05   -0.018674\n",
       "2000-04-06    0.827845\n",
       "2000-04-07    0.565549\n",
       "2000-04-08    1.834914\n",
       "2000-04-09   -3.261648\n",
       "Freq: D, Length: 100, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-31   -0.076557\n",
       "2000-02-29   -0.042131\n",
       "2000-03-31   -0.002186\n",
       "2000-04-30   -0.081508\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01   -0.076557\n",
       "2000-02   -0.042131\n",
       "2000-03   -0.002186\n",
       "2000-04   -0.081508\n",
       "Freq: M, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-01-01 00:00:00', '2000-01-01 00:01:00',\n",
       "               '2000-01-01 00:02:00', '2000-01-01 00:03:00',\n",
       "               '2000-01-01 00:04:00', '2000-01-01 00:05:00',\n",
       "               '2000-01-01 00:06:00', '2000-01-01 00:07:00',\n",
       "               '2000-01-01 00:08:00', '2000-01-01 00:09:00',\n",
       "               '2000-01-01 00:10:00', '2000-01-01 00:11:00'],\n",
       "              dtype='datetime64[ns]', freq='T')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-01 00:00:00     0\n",
       "2000-01-01 00:01:00     1\n",
       "2000-01-01 00:02:00     2\n",
       "2000-01-01 00:03:00     3\n",
       "2000-01-01 00:04:00     4\n",
       "2000-01-01 00:05:00     5\n",
       "2000-01-01 00:06:00     6\n",
       "2000-01-01 00:07:00     7\n",
       "2000-01-01 00:08:00     8\n",
       "2000-01-01 00:09:00     9\n",
       "2000-01-01 00:10:00    10\n",
       "2000-01-01 00:11:00    11\n",
       "Freq: T, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1999-12-31 23:55:00     0\n",
       "2000-01-01 00:00:00    15\n",
       "2000-01-01 00:05:00    40\n",
       "2000-01-01 00:10:00    11\n",
       "Freq: 5T, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2000-01-01 00:00:00     0\n",
       "2000-01-01 00:05:00    15\n",
       "2000-01-01 00:10:00    40\n",
       "2000-01-01 00:15:00    11\n",
       "Freq: 5T, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JBarr\\anaconda3\\envs\\dev\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: 'loffset' in .resample() and in Grouper() is deprecated.\n",
      "\n",
      ">>> df.resample(freq=\"3s\", loffset=\"8H\")\n",
      "\n",
      "becomes:\n",
      "\n",
      ">>> from pandas.tseries.frequencies import to_offset\n",
      ">>> df = df.resample(freq=\"3s\").mean()\n",
      ">>> df.index = df.index.to_timestamp() + to_offset(\"8H\")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1999-12-31 23:59:59     0\n",
       "2000-01-01 00:04:59    15\n",
       "2000-01-01 00:09:59    40\n",
       "2000-01-01 00:14:59    11\n",
       "Freq: 5T, dtype: int32"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 11.6 Resampling and Frequency Conversion\n",
    "Resampling refers to the process of converting a time series from one frequency to another.\n",
    "Aggregating higger frequency data to lower frequency is called downsampling, Upsampling for opposite.\n",
    "\n",
    "using [resample] has a similar API to groupby; you call resample to group the data, then an aggregation function.\n",
    "\"\"\"\n",
    "\n",
    "rng = pd.date_range('2000-01-01', periods=100, freq='D')\n",
    "\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "\n",
    "display(ts)\n",
    "\n",
    "display(ts.resample('M').mean())\n",
    "\n",
    "display(ts.resample('M', kind='period').mean()) # resample method arguments page 355\n",
    "\n",
    "# Downsampling \n",
    "\n",
    "down_rng = pd.date_range('2000-01-01', periods=12, freq='T')\n",
    "\n",
    "down_ts = pd.Series(np.arange(12), index=down_rng)\n",
    "\n",
    "display(down_rng, down_ts)\n",
    "\n",
    "# Suppose you wanted to aggregate this data into five-minute chunks bars by taking the sum of each group:\n",
    "\n",
    "display(down_ts.resample('5min', closed='right').sum())\n",
    "\n",
    "# by passing label='right' you can label them with thr right bin edge:\n",
    "\n",
    "display(down_ts.resample('5min', closed='right', label='right').sum())\n",
    "\n",
    "# To shift the reslut index by some amount, say subtracting one second form the right edge\n",
    "# to make it more clear which interval the timestamp refers to. To do this, pass a string \n",
    "# or date offset to loffset:\n",
    "\n",
    "display(down_ts.resample('5min', closed='right',\n",
    "                        label='right', loffset='-1s').sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e6e1d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Texas</th>\n",
       "      <th>New York</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.712337</td>\n",
       "      <td>-0.708974</td>\n",
       "      <td>-1.067407</td>\n",
       "      <td>0.250142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>1.927968</td>\n",
       "      <td>0.404706</td>\n",
       "      <td>-1.449387</td>\n",
       "      <td>1.097968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Colorado     Texas  New York      Ohio\n",
       "2000-01-05 -0.712337 -0.708974 -1.067407  0.250142\n",
       "2000-01-12  1.927968  0.404706 -1.449387  1.097968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Texas</th>\n",
       "      <th>New York</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.712337</td>\n",
       "      <td>-0.708974</td>\n",
       "      <td>-1.067407</td>\n",
       "      <td>0.250142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>1.927968</td>\n",
       "      <td>0.404706</td>\n",
       "      <td>-1.449387</td>\n",
       "      <td>1.097968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Colorado     Texas  New York      Ohio\n",
       "2000-01-05 -0.712337 -0.708974 -1.067407  0.250142\n",
       "2000-01-06       NaN       NaN       NaN       NaN\n",
       "2000-01-07       NaN       NaN       NaN       NaN\n",
       "2000-01-08       NaN       NaN       NaN       NaN\n",
       "2000-01-09       NaN       NaN       NaN       NaN\n",
       "2000-01-10       NaN       NaN       NaN       NaN\n",
       "2000-01-11       NaN       NaN       NaN       NaN\n",
       "2000-01-12  1.927968  0.404706 -1.449387  1.097968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Colorado</th>\n",
       "      <th>Texas</th>\n",
       "      <th>New York</th>\n",
       "      <th>Ohio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>-0.712337</td>\n",
       "      <td>-0.708974</td>\n",
       "      <td>-1.067407</td>\n",
       "      <td>0.250142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>-0.712337</td>\n",
       "      <td>-0.708974</td>\n",
       "      <td>-1.067407</td>\n",
       "      <td>0.250142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>-0.712337</td>\n",
       "      <td>-0.708974</td>\n",
       "      <td>-1.067407</td>\n",
       "      <td>0.250142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-08</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-09</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-12</th>\n",
       "      <td>1.927968</td>\n",
       "      <td>0.404706</td>\n",
       "      <td>-1.449387</td>\n",
       "      <td>1.097968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Colorado     Texas  New York      Ohio\n",
       "2000-01-05 -0.712337 -0.708974 -1.067407  0.250142\n",
       "2000-01-06 -0.712337 -0.708974 -1.067407  0.250142\n",
       "2000-01-07 -0.712337 -0.708974 -1.067407  0.250142\n",
       "2000-01-08       NaN       NaN       NaN       NaN\n",
       "2000-01-09       NaN       NaN       NaN       NaN\n",
       "2000-01-10       NaN       NaN       NaN       NaN\n",
       "2000-01-11       NaN       NaN       NaN       NaN\n",
       "2000-01-12  1.927968  0.404706 -1.449387  1.097968"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Open-High-Low-Close (OHLC) resampling\n",
    "\n",
    "In finance, a popular way to aggregate a time series is to compute  four values for each bucket:\n",
    "Using the ohlc aggregate fucntion you will obtain a df having columns containing these four aggregates\n",
    "which are computed in a single sweep of data\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "ohlc = down_ts.resample('5min').ohlc()\n",
    "\n",
    "ohlc\n",
    "\n",
    "# Upsampling and Interpolation: Converting for low to higher frequency, no aggregation is needed\n",
    "\n",
    "frame = pd.DataFrame(np.random.randn(2,4),\n",
    "                    index=pd.date_range('1/1/2000',\n",
    "                     periods=2,\n",
    "                     freq='W-WED'),\n",
    "                     columns=['Colorado','Texas' ,'New York', 'Ohio'])\n",
    "\n",
    "display(frame)\n",
    "\n",
    "# When using an aggregation function with this data, there is only one value per group,\n",
    "# and missing values result in the gaps. we use the as freq method to convert to the higher frequency\n",
    "# without any aggregation:\n",
    "\n",
    "df_daily = frame.resample('D').asfreq()\n",
    "\n",
    "display(df_daily)\n",
    "\n",
    "# You can choose to only fill a certain number of periods forward to limit\n",
    "# how far to continue using an observed value:\n",
    "\n",
    "display(frame.resample('D').ffill(limit=2))\n",
    "\n",
    "# Resampling with Periods\n",
    "\n",
    "# SInce periods refer to timespans, the rules about upsampling and downsampling are more rigid:\n",
    "#   * In down, the target freuency must be a subperiod of the source frequency\n",
    "#   * In upsampling, the target frequency must be a superperiod of the source frequency \n",
    "# If these rules are not satisfied an exception will be raised.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4115322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Moving Window Function\n",
    "\n",
    "An important class of array transformation used fopr time series operations\n",
    "are stsistcs and other functions evaluated over a sliding window or\n",
    "with exponentially decaying weights. Good for smoothing noisy or gappy data. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "close_px = pd.read_csv('sp500_closefull.csv',\n",
    "                      parse_dates=True,\n",
    "                      infer_datetime_format=True,\n",
    "                      index_col=['Date'])\n",
    "\n",
    "close_df = close_px[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb100d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b0c06452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Date'>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tickers_df = close_df[[\n",
    "          'TPR']]\n",
    "\n",
    "tickers_df.rolling(250).std().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f7c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52809eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0395abc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81a47d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
